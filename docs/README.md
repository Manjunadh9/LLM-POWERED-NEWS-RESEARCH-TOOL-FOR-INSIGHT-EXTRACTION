# ğŸ”¬ LLM-Powered News Research Tool

> **AI-driven article analysis and insight extraction using Google Gemini, FAISS vector search, and Streamlit**

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.0%2B-red.svg)](https://streamlit.io)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)](https://langchain.com)
[![Google Gemini](https://img.shields.io/badge/Google%20Gemini-AI-orange.svg)](https://ai.google.dev)

---

## ğŸš€ **Features**

### **Core Capabilities**
- ğŸ“° **Multi-URL Processing** - Analyze 1-10 news articles simultaneously
- ğŸ” **Vector Search** - FAISS-powered semantic search with FastEmbed embeddings
- ğŸ¤– **AI Q&A** - Google Gemini AI with automatic model fallback
- ğŸ“Š **Source Attribution** - Expandable source previews with citations
- âš¡ **Rate Limiting** - Built-in API rate limit handling and optimization

### **Technical Stack**
- **Frontend**: Streamlit with modern UI
- **AI/ML**: Google Gemini (Flash/Pro), LangChain, FastEmbed
- **Vector DB**: FAISS with persistent storage
- **Processing**: Unstructured, BeautifulSoup, html2text

---

## ğŸ“‹ **Quick Start**

### **1. Prerequisites**
- **Python 3.10-3.12** (recommended)
- **Google Gemini API Key** ([Get yours here](https://makersuite.google.com/app/apikey))

### **2. Installation**
```powershell
# Clone/navigate to project
cd "C:\Users\<your-username>\OneDrive\Documents\minor-2\Source Code"

# Install dependencies
pip install -r requirements.txt
```

### **3. Configuration**
Create `.env` file:
```env
GEMINI_API_KEY=your_actual_api_key_here
```

### **4. Run Application**
```powershell
# Option 1: Using PowerShell script (Recommended)
.\start_app.ps1

# Option 2: Direct command
python -m streamlit run main.py --server.port 8501
```

**Access:** http://localhost:8501

---

## ğŸ¯ **Usage Guide**

### **Step 1: Add Articles**
- Set number of URLs (1-10) in sidebar
- Paste news article URLs
- Click **"Process URLs"**

### **Step 2: Ask Questions**
- Type questions about processed content
- Get AI-powered answers with source citations
- View expandable source previews

### **Step 3: Analyze Results**
- Review AI responses with confidence scores
- Check source attributions
- Explore related content chunks

---

## ğŸ› ï¸ **Project Structure**

```
Source Code/
â”œâ”€â”€ main.py                 # ğŸ¯ Main Streamlit application
â”œâ”€â”€ start_app.ps1          # ğŸš€ PowerShell startup script
â”œâ”€â”€ rate_limit_helper.py   # âš¡ API rate limit utilities
â”œâ”€â”€ requirements.txt       # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env                   # ğŸ” Environment variables (create this)
â”œâ”€â”€ .env.template         # ğŸ“ Environment template
â”œâ”€â”€ data/                 # ğŸ’¾ Generated data storage
â”‚   â””â”€â”€ faiss_index/      # ğŸ” Vector index files
â””â”€â”€ venv/                 # ğŸ Virtual environment (optional)
```

---

## âš™ï¸ **Configuration**

### **Environment Variables**
| Variable | Description | Required |
|----------|-------------|----------|
| `GEMINI_API_KEY` | Google Gemini API key | âœ… Yes |

### **Model Settings**
- **Primary**: `gemini-1.5-flash` (fast, cost-effective)
- **Fallback**: `gemini-1.5-pro` â†’ `gemini-1.0-pro`
- **Chunk Size**: 200 tokens (optimized for rate limits)
- **Temperature**: 0.7 (balanced creativity)

---

## ğŸ”§ **Troubleshooting**

### **Common Issues**

#### **âŒ Missing API Key**
```
Missing GEMINI_API_KEY environment variable
```
**Solution**: Create `.env` file with your API key and restart

#### **âŒ Unicode Decode Error**
```
UnicodeDecodeError: 'utf-8' codec can't decode
```
**Solution**: App has built-in fallback - refresh browser

#### **âŒ Port Already in Use**
```
Port 8501 is already in use
```
**Solution**: Use alternative port:
```powershell
python -m streamlit run main.py --server.port 8502
```

#### **âŒ Rate Limit Exceeded**
```
API Rate Limit Exceeded
```
**Solution**: Wait 1 minute or upgrade API plan

### **Performance Tips**
- ğŸ”¥ **Use smaller batches** (3-5 URLs max)
- â±ï¸ **Wait between requests** (free tier: 15/min)
- ğŸ“ **Shorter questions** reduce token usage
- ğŸ”„ **Clear index** (`data/faiss_index/`) to rebuild

---

## ğŸ“Š **API Limits & Costs**

### **Free Tier Limits**
- **Requests**: 15/minute, 1,500/day
- **Tokens**: 50,000 input/minute, 15M/day

### **Optimization Features**
- âœ… Automatic model fallback
- âœ… Rate limit detection
- âœ… Token usage optimization
- âœ… Chunking size control

---

## ğŸš€ **Advanced Usage**

### **Custom Configuration**
Modify `main.py` for:
- **Different models**: Change `ChatGoogleGenerativeAI(model=...)`
- **Chunk sizes**: Adjust `chunk_size` and `chunk_overlap`
- **Temperature**: Modify `temperature` for creativity control

### **Batch Processing**
```python
# Process multiple article sets
# 1. Process first batch of URLs
# 2. Ask questions
# 3. Clear index: delete data/faiss_index/
# 4. Process next batch
```

---

## ğŸ“š **Dependencies**

### **Core Libraries**
```txt
streamlit              # Web interface
langchain             # LLM framework
langchain-community   # Community integrations
langchain-google-genai # Google AI integration
faiss-cpu            # Vector search
fastembed            # Fast embeddings
```

### **Processing Libraries**
```txt
unstructured         # Document parsing
html2text           # HTML to text conversion
beautifulsoup4      # Web scraping
lxml                # XML/HTML parser
python-dotenv       # Environment management
```

---

## ğŸ” **Security & Best Practices**

### **API Key Security**
- âœ… Use `.env` file (never commit to git)
- âœ… Keep API keys private
- âœ… Monitor usage and costs
- âœ… Rotate keys periodically

### **Data Privacy**
- ğŸ“ Local vector storage (`data/faiss_index/`)
- ğŸ”’ No data sent to external services (except Gemini API)
- ğŸ—‘ï¸ Clear index to remove processed content

---

## ğŸ¨ **Features Showcase**

### **Smart Processing**
- **Multi-format support**: HTML, text, structured content
- **Intelligent chunking**: Optimized for semantic search
- **Persistent storage**: FAISS index saved locally

### **AI-Powered Analysis**
- **Context-aware responses**: Understands article relationships
- **Source attribution**: Direct links to original content
- **Confidence scoring**: Transparent AI reasoning

### **User Experience**
- **Real-time feedback**: Processing status and progress
- **Error handling**: Graceful degradation and recovery
- **Mobile responsive**: Works on all devices

---

## ğŸ“ˆ **Performance Metrics**

- **Processing Speed**: ~2-5 seconds per article
- **Query Response**: ~1-3 seconds
- **Memory Usage**: ~100-200MB
- **Storage**: ~1-5MB per 10 articles

---

## ğŸ¤ **Contributing**

### **Development Setup**
```powershell
# Create development environment
python -m venv venv
pip install -r requirements.txt

# Run in development mode
streamlit run main.py --server.runOnSave true
```

### **Code Style**
- Follow PEP 8 standards
- Use type hints where applicable
- Add docstrings for functions
- Test with multiple article sources

---

## ğŸ“ **Support**

### **Getting Help**
- ğŸ“– Check troubleshooting section above
- ğŸ› Report issues with error logs
- ğŸ’¡ Feature requests welcome
- ğŸ“§ Contact: [Your contact info]

### **Useful Links**
- [Google AI Studio](https://makersuite.google.com/app/apikey) - Get API key
- [Streamlit Docs](https://docs.streamlit.io) - Framework documentation
- [LangChain Docs](https://python.langchain.com) - LLM framework guide

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Made with â¤ï¸ using Google Gemini AI, LangChain, and Streamlit**
